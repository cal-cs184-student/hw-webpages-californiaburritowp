<html>
	<head>
		<script src='https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.4/MathJax.js?config=default'></script>
		<link href="https://fonts.googleapis.com/css2?family=Inter:wght@400;600&display=swap" rel="stylesheet">
		<style>
			h1 {
				text-align: center;
			}

			.container {
				margin: 0 auto;
				padding: 60px 20%;
			}

			figure {
				text-align: center;
			}

			img {
				display: inline-block;
			}

			body {
				font-family: 'Inter', sans-serif;
			}
		</style>
	</head>
	<body>
		<div class="container">
		<h1>CS184/284A Spring 2025 Homework 2 Write-Up</h1>
		<div style="text-align: center;">By: Nicholas Kiani </div>

		<br>

		Link to webpage: <a href="https://cal-cs184-student.github.io/hw-webpages-californiaburritowp/">cal-cs184-student.github.io/hw-webpages-californiaburritowp/</a>

		<br>
		

		<figure>
			<img src="cornell.png" alt="cornell" style="width:50%"/>
			<figcaption>"Welcome to Wonderland"</figcaption>
		</figure>

		<!--
		We've already added one heading per part, to make your write-up as navigable when grading. Please fit your write-up within these sections!
		-->

		<h2>Overview</h2>
		<p>This write-up details my implementation of several algorithms and programs to render scenes both in a more efficient and physically accurate manner.
			In Part 1, I implemented ray generation and primitive intersections and verified the basics with normal shading on small .dae files. In Part 2, I 
			built a BVH using a splitting heuristic to accelerate my intersection tests for complex scenes and demonstrated its significant rendering time benefits. 
			For Part 3, I implemented two direct lighting techniques (uniform hemisphere sampling and importance sampling), and found that importance sampling 
			produces lower noise in soft shadows when varying the number of light rays. In Part 4, I extended the renderer to include global illumination by 
			recursively tracing indirect bounces using BSDF sampling and Russian Roulette termination, demonstrating how higher-order bounces contribute to more realistic lighting. 
			Finally, Part 5 introduced adaptive sampling, which adjusts the sample rate per pixel dynamically based on local variance to reduce noise 
			without excessive computation.


		</p>
		<p>I learned a lot about how realistic representations of real world lighting in graphics work through this assignment. Unfortunately, I struggled a lot with
			debugging and, as a result, time to complete the assignment itself, and did not end up being able to properly render all the images or complete parts 4 and 5.
			For the time I did spend making progress on the project, I did learn a lot about rendering optimizations. 
		</p>
        
        
        
    
		<h2>Part 1: Ray Generation and Scene Intersection</h2>
		In the rendering pipeline, the role of ray generation is to set up the rays for use. The primitive intersection phase tests each ray for collision with scene primitives using efficient algorithms - for example, in my implementation I used Moller-Trumbore for triangles. These intersections are used to determine color contributions to the pixels we eventually render.
		<p>The triangle intersection algorithm I implemented, Moller-Trumbore, takes a scene triangle's edge vectors and a ray. First, it checks for a determinant of 0, 
		meaning a ray parallel to the triangle; in this case there is no intersection. Then it calculates the barycentric coordinates as well as intersection time t,
		using them to determine if the ray enters the triangle's plane inside/outside the triangle and if the intersection happens between the ray's start and end points.</p>
		
		<div style="display: flex; flex-direction: column; align-items: center;">
			<table style="width: 100%; text-align: center; border-collapse: collapse;">
			  <tr>
				<td style="text-align: center;">
				  <img src="1.png" width="400px"/>
				  <figcaption>First call to evaluateStep.</figcaption>
				</td>
				<td style="text-align: center;">
				  <img src="2.png" width="400px"/>
				  <figcaption>Level 2.</figcaption>
				</td>
			  </tr>
			  <tr>
				<td style="text-align: center;">
				  <img src="3.png" width="400px"/>
				  <figcaption>Level 3.</figcaption>
				</td>
			  </tr>
			</table>
		</div>

		<h3>Part 2: Bounding Volume Hierarchy</h3>
		<p> My BVH construction algorithm recursively subdivides the set of primitives; each call, it finds 
			the Bounding Box of the current set of primitives and selects the longest axis for division. 
			Then, it calculates the heuristic: it averages the centroids of the primitives along
			that axis, setting the split point to that average to partition the set into even groups.
		</p>
		
		<p>To compare runtimes, I have detailed the rendering runtimes of a few medium sized scenes.
		My implementation rendered Maxplanck.dae in 626.3842s seconds without BVH acceleration, 0.1632 seconds with it.
		It rendered Peter.dae in 452.2540 seconds without BVH acceleration, 0.1111 sec seconds with it.
		It rendered Beast.dae in 642.2554 seconds without BVH acceleration, 0.1393 seconds with it. As you can see from the numbers, 
		the BVH acceleration speeds up the rendering process by around 4000 times, bringing an otherwise impractically long
		rendering process significantly closer to one we might be able to use in something like video games. This large result comes from the
		fact that, without some sort of acceleration similar to the BVH we used, all primitives are being checked for intersection with
		each ray that is used to render each pixel. With the optimization, we narrow down which primitives need to be checked first,
		saving time exponentially.
		</p>
		
		<p> Below are a few screenshots of some large images rendered using BVH acceleration. </p>
		
		<div style="display: flex; flex-direction: column; align-items: center;">
			<table style="width: 100%; text-align: center; border-collapse: collapse;">
			  <tr>
				<td style="text-align: center;">
				  <img src="10.png" width="400px"/>
				  <figcaption>Wall-e</figcaption>
				</td>
				<td style="text-align: center;">
				  <img src="11.png" width="400px"/>
				  <figcaption>CBLucy</figcaption>
				</td>
			  </tr>
			  <tr>
				<td style="text-align: center;">
				  <img src="12.png" width="400px"/>
				  <figcaption>CBdragon</figcaption>
				</td>
			  </tr>
			</table>
		</div>

		<h3>Part 3: Direct Illumination</h3>
		<p>The importance sampling implementation directly samples the light sources rather than uniformly sampling directions over the hemisphere. 
		For each light in the scene, the algorithm determines whether the light is a point light or an area light, then generates a direction from 
		the hit point toward the light, along with the distance and PDF of the sample. A shadow ray is cast toward the light, and if no occlusion 
		is found and the light is in front of the surface, the BSDF is evaluated. The contribution from the light is computed according to the reflection equation. 
		Area lights are sampled multiple times and averaged, whereas point lights require only one sample. Importance sampling generally 
		reduces noise since samples are concentrated on areas with higher levels of illumination.
		</p>
		<p>The hemisphere sampling implementation, on the other hand, uniformly samples directions over the hemisphere around a point of interest to 
		find out how much light is reflected to the camera. The renderer uses UniformHemisphereSampler3D::get_sample() to generate a number of random 
		directions over the hemisphere. For each direction, a shadow ray is cast from the hit point (offset by EPS_F to avoid self-intersections) to 
		check for occlusion. If the ray reaches a light source without hitting any blocking primitives, the renderer evaluates the BSDF using the 
		incoming (sampled) and outgoing directions in the reflection equation approximated with a Monte Carlo estimator, averaging the 
		contributions over the total number of samples. This method is simple and general but can be inefficient because many sampled directions may not 
		hit any light at all—resulting in higher noise in soft shadow regions.
		</p>
		<p> The below image examples (a mix of importance and hemisphere sampling) were generated with the same settings: 
			"-t 8","-s 16","-l 32","-r 480 360" </p>
		<div style="display: flex; flex-direction: column; align-items: center;">
			<table style="width: 100%; text-align: center; border-collapse: collapse;">
			  <tr>
				<td style="text-align: center;">
				  <img src="14I.png" width="400px"/>
				  <figcaption>CBbunny: Importance Sampling.</figcaption>
				</td>
				<td style="text-align: center;">
				  <img src="14H.png" width="400px"/>
				  <figcaption>CBbunny: Hemisphere Sampling.</figcaption>
				</td>
			  </tr>
			  <tr>
				<td style="text-align: center;">
				  <img src="13I.png" width="400px"/>
				  <figcaption>CBSpheres_lambertian: Importance Sampling.</figcaption>
				</td>
				<td style="text-align: center;">
				  <img src="13H.png" width="400px"/>
				  <figcaption>CBSpheres_lambertian: Hemisphere Sampling.</figcaption>
				</td>
			  </tr>
			</table>
		</div>
		<p> The below screenshots compare the noise levels in soft shadows when rendering with 1, 4, 16, and 64 light rays and with 1 sample per pixel using light sampling: 
			 </p>
		<div style="display: flex; flex-direction: column; align-items: center;">
			<table style="width: 100%; text-align: center; border-collapse: collapse;">
			  <tr>
				<td style="text-align: center;">
				  <img src="15.png" width="400px"/>
				  <figcaption>CBbunny: 1 light ray.</figcaption>
				</td>
				<td style="text-align: center;">
				  <img src="16.png" width="400px"/>
				  <figcaption>CBbunny: 4 light rays.</figcaption>
				</td>
			  </tr><tr>
				<td style="text-align: center;">
				  <img src="17.png" width="400px"/>
				  <figcaption>CBbunny: 16 light rays.</figcaption>
				</td>
				<td style="text-align: center;">
				  <img src="18.png" width="400px"/>
				  <figcaption>CBbunny: 32 light rays.</figcaption>
				</td>
			  </tr>
			</table>
		</div>
		<p> Analysis: Comparing uniform hemisphere sampling to light sampling, both methods converge to the same physically correct 
			solution. However, uniform hemisphere sampling often has higher noise for the same sample count because it spends 
			many samples on directions that do not contribute significantly. Light sampling, on the other hand, “spends” its samples 
			more efficiently since it focuses on directions most likely to carry significant radiance from the lights, leading to cleaner 
			renders and faster convergence in most practical scenarios.</p>

		<h3>Part 4: Global Illumination</h3>
		<p>In our indirect lighting function, we first build a local coordinate system at the hit point and sample a new direction from the BSDF, 
			then convert that sample to world space to form a new bounce ray. Then we apply Russian Roulette to probabilistically terminate the 
			recursion—if the path survives, we normalize the recursive radiance contribution by the survival probability to keep the 
			estimate unbiased. Finally, the function accumulates the direct lighting from the current bounce with the recursively computed indirect 
			lighting, yielding the full multi-bounce contribution. 
		</p>
		<p>See screenshots below of some scenes rendered using a combination of our previous (direct) and indirect lighting.
		</p>
		<div style="display: flex; flex-direction: column; align-items: center;">
			<table style="width: 100%; text-align: center; border-collapse: collapse;">
			  <tr>
				<td style="text-align: center;">
				  <img src="19.png" width="400px"/>
				  <figcaption>Bench.</figcaption>
				</td>
				<td style="text-align: center;">
				  <img src="20.png" width="400px"/>
				  <figcaption>Coil.</figcaption>
				</td>
			  </tr>
			</table>
		</div>
		<p> The rest of Part 4 I was unable to finish because I could not fix an issue where my brightness was constantly too high for scenes my implementation was rendering.
			I thought putting the time to render such large files would be moot given I know my implementation is not fully correct anyways. But I did enjoy learning about the
			process and I do think I gained a lot from doing this homework, ony I wish I had more time / it was assigned with midterms in mind.
		</p>
		<h3>Part 5: Adaptive Sampling</h3>
		<p> I did not make it to this part of the homework due to my inability to figure out my issues with Part 4 in the time allotted.</p>
		
		
	</body>
</html>